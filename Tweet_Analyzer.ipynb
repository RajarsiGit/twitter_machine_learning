{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import twitter, re, datetime, pandas as pd\n",
    "from TweetMiner import TweetMiner\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "from textacy.preprocess import preprocess_text\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twitter keys and initializing twitter api\n",
    "twitter_keys = {\n",
    "    'consumer_key': 'hnjxcdFF4Bs3DiomJc8ayCq3J',\n",
    "    'consumer_secret': 'K9BxNO6j8PIQ97WGxoUShD3dC3Oue7IXEWkxeLcId279epEQEx',\n",
    "    'access_token_key': '1180916834-JqjE84dTaSXMZkzEaXS0PyeBfQdcJOAL3mVDjWl',\n",
    "    'access_token_secret': 'IdH9yFykUtYmzuuwYUHrTf7DoNbuMlI7cGn27nSU3RJ62'\n",
    "}\n",
    "\n",
    "api = twitter.Api(\n",
    "    consumer_key = twitter_keys['consumer_key'],\n",
    "    consumer_secret = twitter_keys['consumer_secret'],\n",
    "    access_token_key = twitter_keys['access_token_key'],\n",
    "    access_token_secret = twitter_keys['access_token_secret'],\n",
    "    tweet_mode = 'extended'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using TeetMiner function from Mike Roman\n",
    "miner = TweetMiner(api, result_limit=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "hillary = miner.mine_user_tweets(user=\"HillaryClinton\")\n",
    "donald = miner.mine_user_tweets(user=\"realDonaldTrump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df = pd.DataFrame(donald)\n",
    "hillary_df = pd.DataFrame(hillary)\n",
    "tweets = pd.concat([trump_df, hillary_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding ngrams for us\n",
    "vect = TfidfVectorizer(ngram_range=(2, 5), stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#most common tweets of Trump\n",
    "summaries = \"\".join(trump_df['text'])\n",
    "ngrams_summaries = vect.build_analyzer()(summaries)\n",
    "trump_most_common = Counter(ngrams_summaries).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#most common tweets of Hillary\n",
    "summaries = \"\".join(hillary_df['text'])\n",
    "ngrams_summaries = vect.build_analyzer()(summaries)\n",
    "hillary_most_common = Counter(ngrams_summaries).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning text data using textacy\n",
    "tweet_text = tweets['text'].values\n",
    "clean_text = [preprocess_text(x, fix_unicode=True, lowercase=True, no_urls=True, no_emails=True, no_phone_numbers=True, no_currency_symbols=True, no_punct=True, no_accents=True) for x in tweet_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating target\n",
    "y = tweets['handle'].map(lambda x: 1 if x == 'realDonaldTrump' else 0).values\n",
    "#print(max(pd.Series(y).value_counts(normalize=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorizing with TF-IDF Vectorizer and creating X matrix\n",
    "tfv = TfidfVectorizer(ngram_range=(2, 4), max_features=2000)\n",
    "X = tfv.fit_transform(clean_text).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 2000 out of 2000 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': array([1.00000000e-05, 1....\n",
       "       1.74752840e-01, 1.96304065e-01, 2.20513074e-01, 2.47707636e-01,\n",
       "       2.78255940e-01, 3.12571585e-01, 3.51119173e-01, 3.94420606e-01,\n",
       "       4.43062146e-01, 4.97702356e-01, 5.59081018e-01, 6.28029144e-01,\n",
       "       7.05480231e-01, 7.92482898e-01, 8.90215085e-01, 1.00000000e+00]),\n",
       "                         'penalty': ['l2', 'l1'], 'solver': ['liblinear']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "params = {'penalty': ['l2', 'l1'], 'C':np.logspace(-5,0,100), 'solver': ['liblinear']}\n",
    "#Grid searching to find optimal parameters for Logistic Regression\n",
    "gs = GridSearchCV(lr, param_grid=params, cv=10, verbose=1)\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.8902150854450392, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "0.8298994974874372\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_params_)\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = cross_val_score(lr, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8296482412060302\n",
      "0.6407035175879396\n"
     ]
    }
   ],
   "source": [
    "print(accuracies.mean())\n",
    "print(1-y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = LogisticRegression(penalty='l2', C=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(X, y)\n",
    "\n",
    "# Prep our source as TfIdf vectors\n",
    "source_test = [\n",
    "    \"The presidency doesn’t change who you are—it reveals who you are. And we’ve seen all we need to of Donald Trump.\",\n",
    "    \"I will be interviewed on @foxandfriends at 8:00 A.M. Enjoy!\"\n",
    "]\n",
    "Xtest = tfv.transform(source_test)\n",
    "probab = pd.DataFrame(estimator.predict_proba(Xtest), columns=[\"Proba_Hillary\", \"Proba_Trump\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Proba_Hillary  Proba_Trump\n",
      "0       0.905306     0.094694\n",
      "1       0.179177     0.820823\n"
     ]
    }
   ],
   "source": [
    "print(probab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the tweets that have the highest and lowest probability of being from Trump or Hillary based on the model\n",
    "Probas_x = pd.DataFrame(estimator.predict_proba(X), columns=[\"Proba_Hillary\", \"Proba_Donald\"])\n",
    "joined_x = pd.merge(tweets, Probas_x, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_hillary = joined_x[joined_x['handle']==\"HillaryClinton\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBT kids are perfect exactly the way they are. #BornPerfect https://t.co/FFylqTxG5b\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for el in joined_hillary[joined_hillary['Proba_Hillary']==max(joined_hillary['Proba_Hillary'])]['text']:\n",
    "    print(el, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This hasn't gotten enough attn: For the first time, Congress missed the deadline to reauthorize the Children's Health Insurance Program. 1/7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for el in joined_hillary[joined_hillary['Proba_Hillary']==min(joined_hillary['Proba_Hillary'])]['text']:\n",
    "    print(el, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_donald = joined_x[joined_x['handle']==\"realDonaldTrump\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any fair minded person watching the Senate trial today would be able to see how unfairly I have been treated and that this is indeed the totally partisan Impeachment Hoax that EVERYBODY, including the Democrats, truly knows it is. This should never be allowed to happen again!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for el in joined_donald[joined_donald['Proba_Donald']==max(joined_donald['Proba_Donald'])]['text']:\n",
    "    print(el, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will be interviewed on @foxandfriends at 8:00 A.M. Enjoy!\n",
      "\n",
      "THANK YOU MICHAEL! @bittyandbeaus https://t.co/KVXVcdO79E\n",
      "\n",
      "I will protect your Social Security and Medicare, just as I have for the past 3 years. Sleepy Joe Biden will destroy both in very short order, and he won’t even know he’s doing it!\n",
      "\n",
      "We strongly stand with Terrence! https://t.co/N4uFExD6Vz\n",
      "\n",
      "Set up by Schiff’s lies &amp; leaks. Same with the Mueller Witch Hunt 3 years ago! https://t.co/uSzupeHXoq\n",
      "\n",
      "Heading to New Jersey. Big Rally, in fact, Really Big Rally!\n",
      "\n",
      "It was my honor to welcome our nation’s Mayors to the @WhiteHouse as we continue to strengthen the bonds of cooperation between federal and local governments so that we can deliver great jobs, excellent schools, affordable healthcare, and safe communities for all of our people! https://t.co/QwYzS32lyQ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for el in joined_donald[joined_donald['Proba_Donald']==min(joined_donald['Proba_Donald'])]['text']:\n",
    "    print(el, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
